{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "752fafd9",
      "metadata": {
        "id": "752fafd9"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index transformers neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0a4709",
      "metadata": {
        "id": "6c0a4709",
        "outputId": "d65fa31b-38be-4655-ec85-83b661f3c143"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tomaz/anaconda3/envs/snakes/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "triplet_extractor = pipeline(\n",
        "    'text2text-generation',\n",
        "    model='Babelscape/rebel-large',\n",
        "    tokenizer='Babelscape/rebel-large',\n",
        "    device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e1bc91d",
      "metadata": {
        "id": "2e1bc91d"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "# Function to parse the generated text and extract the triplets\n",
        "# Rebel outputs a specific format. This code is mostly copied from the model card!\n",
        "\n",
        "def clean_triplets(input_text, triplets):\n",
        "    \"\"\"Sometimes the model hallucinates, so we filter out entities\n",
        "       not present in the text\"\"\"\n",
        "    text = input_text.lower()\n",
        "    clean_triplets = []\n",
        "    for triplet in triplets:\n",
        "\n",
        "        if (triplet[\"head\"] == triplet[\"tail\"]):\n",
        "            continue\n",
        "\n",
        "        head_match = re.search(\n",
        "            r'\\b' + re.escape(triplet[\"head\"].lower()) + r'\\b', text)\n",
        "        if head_match:\n",
        "            head_index = head_match.start()\n",
        "        else:\n",
        "            head_index = text.find(triplet[\"head\"].lower())\n",
        "\n",
        "        tail_match = re.search(\n",
        "            r'\\b' + re.escape(triplet[\"tail\"].lower()) + r'\\b', text)\n",
        "        if tail_match:\n",
        "            tail_index = tail_match.start()\n",
        "        else:\n",
        "            tail_index = text.find(triplet[\"tail\"].lower())\n",
        "\n",
        "        if ((head_index == -1) or (tail_index == -1)):\n",
        "            continue\n",
        "\n",
        "        clean_triplets.append((triplet[\"head\"], triplet[\"type\"], triplet[\"tail\"]))\n",
        "\n",
        "    return clean_triplets\n",
        "\n",
        "def extract_triplets(input_text):\n",
        "    text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(input_text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])[0]\n",
        "\n",
        "    triplets = []\n",
        "    relation, subject, relation, object_ = '', '', '', ''\n",
        "    text = text.strip()\n",
        "    current = 'x'\n",
        "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
        "        if token == \"<triplet>\":\n",
        "            current = 't'\n",
        "            if relation != '':\n",
        "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "                relation = ''\n",
        "            subject = ''\n",
        "        elif token == \"<subj>\":\n",
        "            current = 's'\n",
        "            if relation != '':\n",
        "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "            object_ = ''\n",
        "        elif token == \"<obj>\":\n",
        "            current = 'o'\n",
        "            relation = ''\n",
        "        else:\n",
        "            if current == 't':\n",
        "                subject += ' ' + token\n",
        "            elif current == 's':\n",
        "                object_ += ' ' + token\n",
        "            elif current == 'o':\n",
        "                relation += ' ' + token\n",
        "\n",
        "    if subject != '' and relation != '' and object_ != '':\n",
        "        triplets.append({'head': subject.strip(), 'type': relation.strip(), 'tail':object_.strip()})\n",
        "    clean = clean_triplets(input_text, triplets)\n",
        "    return clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efbfa609",
      "metadata": {
        "id": "efbfa609"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Uses openai to generate natural language responses and Cypher statements\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"API-KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e59c834e",
      "metadata": {
        "id": "e59c834e"
      },
      "outputs": [],
      "source": [
        "from llama_index.graph_stores import Neo4jGraphStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "\n",
        "username = \"neo4j\"\n",
        "password = \"retractor-knot-thermocouples\"\n",
        "url = \"bolt://44.211.44.239:7687\"\n",
        "database = \"neo4j\"\n",
        "\n",
        "graph_store = Neo4jGraphStore(\n",
        "    username=username,\n",
        "    password=password,\n",
        "    url=url,\n",
        "    database=database,\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e7b7d62",
      "metadata": {
        "id": "5e7b7d62"
      },
      "outputs": [],
      "source": [
        "from llama_index import KnowledgeGraphIndex, ServiceContext\n",
        "from llama_index import download_loader\n",
        "\n",
        "WikipediaReader = download_loader(\"WikipediaReader\")\n",
        "\n",
        "loader = WikipediaReader()\n",
        "\n",
        "documents = loader.load_data(\n",
        "    pages=[\"The Elder Scrolls V: Skyrim\"], auto_suggest=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03667a2e",
      "metadata": {
        "id": "03667a2e"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms import OpenAI\n",
        "\n",
        "# rebel supports up to 512 input tokens, but shorter sequences also work well\n",
        "llm=OpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=256)\n",
        "\n",
        "# This can take some times\n",
        "index = KnowledgeGraphIndex.from_documents(\n",
        "    documents,\n",
        "    storage_context=storage_context,\n",
        "    kg_triplet_extract_fn=extract_triplets,\n",
        "    service_context=service_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c5de8f",
      "metadata": {
        "id": "52c5de8f",
        "outputId": "6505a414-86dd-4a14-bb30-57307f25e013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33;1m\u001b[1;3mGraph Store Query: \n",
            "MATCH (n:Entity)-[:HIGHEST_POINT]->(m:Entity) WHERE n.id = 'Skyrim' RETURN m.id\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mGraph Store Response: [{'m.id': 'Throat of the World'}]\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mFinal Response: \n",
            "The highest point in Skyrim is the Throat of the World.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "from llama_index.query_engine import KnowledgeGraphQueryEngine\n",
        "\n",
        "query_engine = KnowledgeGraphQueryEngine(\n",
        "    storage_context=storage_context,\n",
        "    service_context=service_context,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    refresh_schema=True\n",
        ")\n",
        "\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"What is the highest point in Skyrim?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "352b8bf4",
      "metadata": {
        "id": "352b8bf4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "firstEnv",
      "language": "python",
      "name": "firstenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}