{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMG/M1a8aMFQoPSEid9bGbj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6f6eb79678446088333637005f52a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a2ca0a3e4b248b4ab12dd0ef3cc7517",
              "IPY_MODEL_990a58de9d1e4eb6ae6e88b4db4be105",
              "IPY_MODEL_ebb39a891a7946488074eaf3504c6d07"
            ],
            "layout": "IPY_MODEL_4e7517577f2641c1b012e6b6d03b628b"
          }
        },
        "6a2ca0a3e4b248b4ab12dd0ef3cc7517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6d2a9ba5a2c40419d48b192223f3679",
            "placeholder": "​",
            "style": "IPY_MODEL_4bc42f252aa04155a5518cdda6597503",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "990a58de9d1e4eb6ae6e88b4db4be105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b92498758e604301939de74bece19d6f",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3254a40dc9b4420f8d9781cef5432d85",
            "value": 8
          }
        },
        "ebb39a891a7946488074eaf3504c6d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2a581abaade4cdc8728f8a0a57c49b3",
            "placeholder": "​",
            "style": "IPY_MODEL_bd43de52f0174f4e927e5de494aa239b",
            "value": " 8/8 [01:23&lt;00:00,  9.31s/it]"
          }
        },
        "4e7517577f2641c1b012e6b6d03b628b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6d2a9ba5a2c40419d48b192223f3679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc42f252aa04155a5518cdda6597503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b92498758e604301939de74bece19d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3254a40dc9b4420f8d9781cef5432d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2a581abaade4cdc8728f8a0a57c49b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd43de52f0174f4e927e5de494aa239b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomasonjo/blogs/blob/master/weaviate/HubermanWeaviate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/aigeek0x0/zephyr-7b-alpha-langchain-chatbot/tree/main"
      ],
      "metadata": {
        "id": "C4eiVWqwrX6K"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "862mrrFarPd8"
      },
      "outputs": [],
      "source": [
        "#install required packages\n",
        "!pip install -q transformers peft accelerate bitsandbytes safetensors sentencepiece streamlit weaviate-client langchain sentence-transformers tiktoken youtube-transcript-api\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WEAVIATE_URL = \"\"\n",
        "WEAVIATE_API_KEY = \"\""
      ],
      "metadata": {
        "id": "UM3cSn_wr0Jf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fixing unicode error in google colab\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "# import dependencies\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.vectorstores import Weaviate\n",
        "import weaviate"
      ],
      "metadata": {
        "id": "SN2uCUePrZAN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify embedding model (using huggingface sentence transformer)\n",
        "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name, model_kwargs=model_kwargs)"
      ],
      "metadata": {
        "id": "HRHRss8Os5M9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "URL = \"https://www.youtube.com/feeds/videos.xml?channel_id=UC2D2CMWXMOVWx7giW1n3LIg\"\n",
        "\n",
        "response = requests.get(URL)\n",
        "xml_data = response.content\n",
        "\n",
        "# Parse the XML data\n",
        "root = ET.fromstring(xml_data)\n",
        "\n",
        "# Define the namespace\n",
        "namespaces = {\n",
        "    'atom': 'http://www.w3.org/2005/Atom',\n",
        "    'media': 'http://search.yahoo.com/mrss/'\n",
        "}\n",
        "\n",
        "# Extract YouTube links\n",
        "youtube_links = [link.get('href') for link in root.findall(\".//atom:link[@rel='alternate']\", namespaces)][1:]"
      ],
      "metadata": {
        "id": "Vv0VIfvYvJ4Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import YoutubeLoader\n",
        "\n",
        "all_docs = []\n",
        "for link in youtube_links:\n",
        "  loader = YoutubeLoader.from_youtube_url(link)\n",
        "  docs = loader.load()\n",
        "  all_docs.extend(docs)\n",
        "text_splitter = TokenTextSplitter(chunk_size=128, chunk_overlap=0)\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "client = weaviate.Client(url=WEAVIATE_URL, auth_client_secret=weaviate.AuthApiKey(WEAVIATE_API_KEY))\n",
        "vector_db = Weaviate.from_documents(split_docs, embeddings, client=client, by_text=False)"
      ],
      "metadata": {
        "id": "xvY4odPpsqFE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db.similarity_search(\"Wassup\", k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-N9EfUBxFov",
        "outputId": "b9de5981-917d-43c4-93a6-34faa8993faf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\" how it stands to\\npotentially transform every aspect of everyday life. Before we begin, I'd\\nlike to emphasize that this podcast is separate\\nfrom my teaching and research roles at Stanford. It is, however, part\\nof my desire and effort to bring zero cost to\\nconsumer information about science and\\nscience-related tools to the general public. In keeping with\\nthat theme, I'd like to thank the sponsors\\nof today's podcast. Our first sponsor\\nis Eight Sleep Eight Sleep makes smart mattress\\ncovers with cooling, heating, and sleep tracking capacity. I've spoken many times before\\non this podcast about\", metadata={'source': '1Wo6SqLNmLk'})]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify model huggingface mode name\n",
        "model_name = \"anakin87/zephyr-7b-alpha-sharded\"\n",
        "\n",
        "# function for loading 4-bit quantized model\n",
        "def load_quantized_model(model_name: str):\n",
        "    \"\"\"\n",
        "    :param model_name: Name or path of the model to be loaded.\n",
        "    :return: Loaded quantized model.\n",
        "    \"\"\"\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        load_in_4bit=True,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        quantization_config=bnb_config\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "EgCf03IZrmbS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for initializing tokenizer\n",
        "def initialize_tokenizer(model_name: str):\n",
        "    \"\"\"\n",
        "    Initialize the tokenizer with the specified model_name.\n",
        "\n",
        "    :param model_name: Name or path of the model for tokenizer initialization.\n",
        "    :return: Initialized tokenizer.\n",
        "    \"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, return_token_type_ids=False)\n",
        "    tokenizer.bos_token_id = 1  # Set beginning of sentence token id\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "CVtXtKn1sKw-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize tokenizer\n",
        "tokenizer = initialize_tokenizer(model_name)\n",
        "# load model\n",
        "model = load_quantized_model(model_name)\n",
        "# specify stop token ids\n",
        "stop_token_ids = [0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e6f6eb79678446088333637005f52a81",
            "6a2ca0a3e4b248b4ab12dd0ef3cc7517",
            "990a58de9d1e4eb6ae6e88b4db4be105",
            "ebb39a891a7946488074eaf3504c6d07",
            "4e7517577f2641c1b012e6b6d03b628b",
            "f6d2a9ba5a2c40419d48b192223f3679",
            "4bc42f252aa04155a5518cdda6597503",
            "b92498758e604301939de74bece19d6f",
            "3254a40dc9b4420f8d9781cef5432d85",
            "a2a581abaade4cdc8728f8a0a57c49b3",
            "bd43de52f0174f4e927e5de494aa239b"
          ]
        },
        "id": "RBKdM3tXsP6K",
        "outputId": "d8883820-2aba-498b-b368-382f15312cc6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6f6eb79678446088333637005f52a81"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build huggingface pipeline for using zephyr-7b-alpha\n",
        "pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        use_cache=True,\n",
        "        device_map=\"auto\",\n",
        "        max_length=2048,\n",
        "        do_sample=True,\n",
        "        top_k=5,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "\n",
        "# specify the llm\n",
        "llm = HuggingFacePipeline(pipeline=pipeline)\n",
        "\n",
        "# build conversational retrieval chain with memory (rag) using langchain\n",
        "def create_conversation(query: str, chat_history: list = []) -> tuple:\n",
        "    try:\n",
        "        qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "            llm=llm,\n",
        "            retriever=vector_db.as_retriever(),\n",
        "            get_chat_history=lambda h: h,\n",
        "        )\n",
        "\n",
        "        result = qa_chain({'question': query, 'chat_history': chat_history})\n",
        "        chat_history.append((query, result['answer']))\n",
        "        return '', chat_history\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        chat_history.append((query, e))\n",
        "        return '', chat_history"
      ],
      "metadata": {
        "id": "VvyYXop3sbXR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_conversation(\"What's Zuckerberg talking about?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL0RIE3cy5BC",
        "outputId": "3aad8219-7924-45f0-f4d0-e5726338206b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('',\n",
              " [(\"What's Zuckerberg talking about?\",\n",
              "   ' Zuckerberg is discussing the CZI, or Chan Zuckerberg Initiative, and its goal to discover new pathways and cures for all human diseases through critical funding and artificial intelligence platforms.')])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uWSirlty1eux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}