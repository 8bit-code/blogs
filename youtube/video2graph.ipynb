{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0LtTIqUH/xM9a+u9LCXJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomasonjo/blogs/blob/master/youtube/video2graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDqgx3RrK3KA",
        "outputId": "08dd77c3-5822-4a13-bc48-ad5baf9fb0c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.2)\n",
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.9/dist-packages (0.5.0)\n",
            "Collecting neo4j\n",
            "  Downloading neo4j-5.6.0.tar.gz (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.2/171.2 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from neo4j) (2022.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Building wheels for collected packages: neo4j\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neo4j: filename=neo4j-5.6.0-py3-none-any.whl size=237773 sha256=528eec35f45810df45c6dc5147c40076d13617e57fdbe32efeb3e36ecab6a52b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/9b/d9/fdb6b67a6f6d7aef4acaefe55f339739caf09bb63e43bfb10e\n",
            "Successfully built neo4j\n",
            "Installing collected packages: neo4j\n",
            "Successfully installed neo4j-5.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai youtube-transcript-api neo4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "uri = \"bolt://18.207.186.117:7687\"\n",
        "username = \"neo4j\"\n",
        "password = \"magazine-scream-roadside\"\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))"
      ],
      "metadata": {
        "id": "stf9vu_mdlBn"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "# CC BY 4 license\n",
        "video_id = \"0ZEBNpiuMu4\"\n",
        "\n",
        "transcript = YouTubeTranscriptApi.get_transcript(video_id)"
      ],
      "metadata": {
        "id": "j_bDji05UECS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into paragraphs and include start and end timestamps\n",
        "paragraphs = []\n",
        "current_paragraph = ''\n",
        "start_time = None\n",
        "\n",
        "for line in transcript:\n",
        "    if '[Music]' in line['text']:\n",
        "        # If we've reached the end of a paragraph, add it to the list of paragraphs\n",
        "        if current_paragraph:\n",
        "            end_time = line['start']\n",
        "            paragraphs.append({\n",
        "                'text': current_paragraph.strip(),\n",
        "                'start_time': start_time,\n",
        "                'end_time': end_time\n",
        "            })\n",
        "            current_paragraph = ''\n",
        "            start_time = None\n",
        "    else:\n",
        "        # If this is the start of a new paragraph, record the start time\n",
        "        if not start_time:\n",
        "            start_time = line['start']\n",
        "        \n",
        "        # Add the line to the current paragraph\n",
        "        current_paragraph += line['text'] + ' '\n",
        "\n",
        "# If there's a paragraph left at the end, add it to the list of paragraphs\n",
        "if current_paragraph:\n",
        "    end_time = transcript[-1]['start'] + transcript[-1]['duration']\n",
        "    paragraphs.append({\n",
        "        'text': current_paragraph.strip(),\n",
        "        'start_time': start_time,\n",
        "        'end_time': end_time\n",
        "    })\n",
        "\n",
        "# Remove empty paragraphs\n",
        "paragraphs = [p for p in paragraphs if p['text']]"
      ],
      "metadata": {
        "id": "MVS38lqEaRbu"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of paragraphs\n",
        "print(f\"Number of paragraphs: {len(paragraphs)}\")\n",
        "print(f\"Max characters per paragraph: {max([len(el['text']) for el in paragraphs])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXp7PwoJVJe9",
        "outputId": "f5430f2c-5cf2-4e66-9455-5c97070c33b8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of paragraphs: 35\n",
            "Max characters per paragraph: 1398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy0sucRDaUPA",
        "outputId": "1f2a8323-76a5-4d64-99ed-bf5a1edbed65"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'it was in one of the galleries of st. Peters mount at about 500 paces from the main entry and at 90 feet below the surface the deployment exposed part of the skull of a large animal embedded in this stone they suspended their work to tell of their discovery to dr. Hoffman who had for some years been collecting fossils from the quarries dr. Hoffman observing a specimen to be the most important that had yet been discovered took every precaution to preserve it in one piece after having succeeded in removing a large block of stone surrounding it and reducing the mass to a proper condition it was transported to his home in triumph',\n",
              " 'start_time': 9.65,\n",
              " 'end_time': 64.069}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_entities_and_relationships(input_str):\n",
        "    # Parse the input string\n",
        "    entities = []\n",
        "    relationships = []\n",
        "    entity_mode = True\n",
        "    # Skip the first line\n",
        "    for line in input_str.split('\\n')[1:]:\n",
        "        if line == 'relationships':\n",
        "            entity_mode = False\n",
        "        elif line:\n",
        "            if entity_mode:\n",
        "                entities.append(line)\n",
        "            else:\n",
        "                relationships.append(line.split(', '))\n",
        "    return entities, relationships"
      ],
      "metadata": {
        "id": "GDqh6TY7dxCq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = \"OPENAI_KEY\"\n",
        "\n",
        "def gpt4archeologist(text):\n",
        "  system = \"You are an archeology and biology expert helping us extract relevant information.\"\n",
        "\n",
        "  # Set up the prompt for GPT-3 to complete\n",
        "  prompt = \"\"\"#This a transcript from a sea documentary. The task is to extract as many relevant entities to biology, chemistry, or archeology.\n",
        "#The entities should include all animals, biological entities, locations.\n",
        "#However, the entities should not include distances or time durations.\n",
        "#Additionally, extract all relevant relationships between identified entities.\n",
        "#The relationships should follow the Wikipedia schema type.\n",
        "#The output of a relationship should be in a form of a triple Head, Relationship, Tail, for example\n",
        "#Peter, WORKS_AT, Hospital/n\n",
        "# An output should be have the following format\n",
        "entity\n",
        "St. Peters Mount\n",
        "galleries\n",
        "\n",
        "relationships\n",
        "large animal, EMBEDDED_IN, stone\\n\"\"\"\n",
        "\n",
        "\n",
        "  paragraph = text\n",
        "\n",
        "  completion = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4\",\n",
        "      temperature=0,\n",
        "      messages=[{\"role\": \"system\", \"content\": system},\n",
        "          {\"role\": \"user\", \"content\": prompt + paragraph}]\n",
        "      )\n",
        "\n",
        "  nlp_results = completion.choices[0].message.content\n",
        "  return parse_entities_and_relationships(nlp_results)"
      ],
      "metadata": {
        "id": "xL35GBGnK43H"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import_query = \"\"\"\n",
        "MERGE (v:Video {id:$videoId})\n",
        "CREATE (v)-[:HAS_SECTION]->(p:Section)\n",
        "SET p.startTime = toFloat($start),\n",
        "    p.endTime = toFloat($end),\n",
        "    p.text = $text\n",
        "FOREACH (e in $entities | MERGE (entity:Entity {name: e}) MERGE (p)-[:MENTIONS]->(entity))\n",
        "WITH p\n",
        "UNWIND $relationships AS relation\n",
        "MERGE (source:Entity {name: relation[0]})\n",
        "MERGE (target:Entity {name: relation[2]})\n",
        "MERGE (source)-[:RELATIONSHIP]->(r:Relationship {type: relation[1]})-[:RELATIONSHIP]->(target)\n",
        "MERGE (p)-[mr:MENTIONS_RELATIONSHIP]->(r)\n",
        "\"\"\"\n",
        "\n",
        "with driver.session() as session:\n",
        "  for i, paragraph in enumerate(paragraphs):\n",
        "    print(f\"Processing {i} paragraph\")\n",
        "    text = paragraph['text']\n",
        "    start = paragraph['start_time']\n",
        "    end = paragraph['end_time']\n",
        "    entities, relationships = gpt4archeologist(text)\n",
        "    params = {'videoId': video_id, 'start': start, 'end': end, 'text':text, 'entities': entities, 'relationships': relationships}\n",
        "    session.run(import_query, params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmdQQnQReMKu",
        "outputId": "6be3f30c-97a8-46f4-c352-4690b5ce6e34"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 0 paragraph\n",
            "Processing 1 paragraph\n",
            "Processing 2 paragraph\n",
            "Processing 3 paragraph\n",
            "Processing 4 paragraph\n",
            "Processing 5 paragraph\n",
            "Processing 6 paragraph\n",
            "Processing 7 paragraph\n",
            "Processing 8 paragraph\n",
            "Processing 9 paragraph\n",
            "Processing 10 paragraph\n",
            "Processing 11 paragraph\n",
            "Processing 12 paragraph\n",
            "Processing 13 paragraph\n",
            "Processing 14 paragraph\n",
            "Processing 15 paragraph\n",
            "Processing 16 paragraph\n",
            "Processing 17 paragraph\n",
            "Processing 18 paragraph\n",
            "Processing 19 paragraph\n",
            "Processing 20 paragraph\n",
            "Processing 21 paragraph\n",
            "Processing 22 paragraph\n",
            "Processing 23 paragraph\n",
            "Processing 24 paragraph\n",
            "Processing 25 paragraph\n",
            "Processing 26 paragraph\n",
            "Processing 27 paragraph\n",
            "Processing 28 paragraph\n",
            "Processing 29 paragraph\n",
            "Processing 30 paragraph\n",
            "Processing 31 paragraph\n",
            "Processing 32 paragraph\n",
            "Processing 33 paragraph\n",
            "Processing 34 paragraph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ig4O9WLihnsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}